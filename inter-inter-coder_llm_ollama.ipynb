{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d75c5f",
   "metadata": {},
   "source": [
    "<h1> INTER_INTER-CODER ANALYSIS </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dde1ddd",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d81ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import pprint as pp\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d1c0d",
   "metadata": {},
   "source": [
    "### MODEL FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebcdd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of test LLMs\n",
    "model_arr = [\n",
    "    'llama3:70b',\n",
    "    'phi3:14b',\n",
    "    'mistral:7b',\n",
    "    'gemma2:27b'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd65e24",
   "metadata": {},
   "source": [
    "### EVALUATE\n",
    "Make sure ollama server is running on the same node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c93152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each model\n",
    "for m in model_arr:  \n",
    "   #create system prompt  \n",
    "   modelfile='''\n",
    "   FROM {}\n",
    "   SYSTEM You are an impartial research assistant evaluating Twitter data collected during the COVID-19 pandemic. The tweets may be serious, humorous, or have nothing to do with COVID-19. \n",
    "   Please take into account links, emojis, hashtags, etc. Please respond with only two items: an integer (0 for 'not related to mask wearing',1 for 'anti-mask', 2 for 'pro-mask', 3 for neutral/uncertain) and a single sentence explaining your rationale. \n",
    "   Format your response as well-formed JSON as follows: {{\"result\":\"1\",\"rationale\":\"the individual hates mask-wearing\"}}\n",
    "   '''.format(m)\n",
    "   #create model based on system prompt\n",
    "   ollama.create(model='{}-crisis-1'.format(m), modelfile=modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad88538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Finally a mask that fits my true personality!!...\n",
       "1       People screaming that we need to reopen school...\n",
       "2       Rosie the Riveter going strong at 94ðŸ‡ºðŸ‡¸ https:/...\n",
       "3       So what happens when the vaccine comes? The an...\n",
       "4       @Walsh_PT I was just saying to my wife that th...\n",
       "                              ...                        \n",
       "2576    @NoNameCalling1 @mcfunny @P8R1OT â€œYou mask wea...\n",
       "2577    @NoNameCalling1 @mcfunny @P8R1OT But letâ€™s set...\n",
       "2578    @NoNameCalling1 @JaneEOpie @mcfunny @TheBaba45...\n",
       "2579    Dear @RepThomasMassie John Locke 'said that a ...\n",
       "2580    And there you have it.\\n@RepThomasMassie can y...\n",
       "Name: full_text, Length: 2581, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in tweet texts\n",
    "df = pd.read_csv('data/mask_tweets.csv',index_col=0)\n",
    "df['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0533b9bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#select the llm under test\n",
    "#!!!!!iterate for each model, n times\n",
    "test_model = model_arr[3]\n",
    "#output data\n",
    "output_dict = []\n",
    "#for each tweet text\n",
    "for row in df.iterrows():\n",
    "    #create buffer\n",
    "    buffer_dict = {}\n",
    "    #note start time\n",
    "    start_time = time.time()\n",
    "    #query ollama for response\n",
    "    response = ollama.chat(model='{}-crisis-1'.format(test_model), messages=[\n",
    "      {\n",
    "          'role': 'user',\n",
    "          'content': 'What is the following Twitter user\\'s attitude towards COVID-19 mask wearing?: {}'.format(row[1][\"full_text\"]),\n",
    "      },\n",
    "    ])\n",
    "    #parse response as json and append to buffer\n",
    "    #if parsing error, log as '-1' and keep the text\n",
    "    try:\n",
    "        buffer_dict = ast.literal_eval(response['message']['content'])\n",
    "    except:\n",
    "        buffer_dict = {\"result\":\"-1\",\"rationale\":response['message']['content']}\n",
    "    #note end time\n",
    "    stop_time = time.time()\n",
    "    #append original tweet information + evaluation time to buffer\n",
    "    buffer_dict[\"tweet_id\"] = row[1][\"id\"]\n",
    "    buffer_dict[\"full_text\"] = row[1][\"full_text\"]\n",
    "    buffer_dict[\"eval_time\"] = stop_time - start_time\n",
    "    #append buffer to output\n",
    "    output_dict.append(buffer_dict)\n",
    "    #for testing\n",
    "    #pp.pprint(buffer_dict)\n",
    "#generate output from output dict and save\n",
    "output_df = pd.DataFrame().from_dict(output_dict)\n",
    "output_df.to_csv('data/output/{}/{}_crisis_1_{}.csv'.format(test_model,test_model,time.time()))\n",
    "output_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
